#cloud-config

write_files:
  - content: |
      - name: install haproxy
        hosts: 127.0.0.1
        pre_tasks:
           - name: stop consul
             service: name=consul state=stopped
           - name: clean /opt/consul/data/serf/local.keyring
             file: path=/opt/consul/data/serf/local.keyring state=absent
        roles:
          - role: ansible-haproxy
            haproxy_user: ${haproxy_user}
            haproxy_pass: ${haproxy_pass}
            haproxy_conf: |
              ${haproxy_conf}
            haproxy_cert:
              ${haproxy_cert}
          - role: entercloudsuite.consul
            consul_config_validate: "{{ consul_user_home }}/bin/consul validate -config-format=json %s"
            consul_configs:
              main:
                bind_addr: 0.0.0.0
                client_addr: 0.0.0.0
                node_name: "{{ ansible_hostname }}"
                data_dir: "{{ consul_data_dir }}"
                encrypt: "${consul_encrypt}"
                datacenter: "${consul_datacenter}"
                enable_syslog: true
                server: false
                ui: true
                enable_script_checks: true
                services:
                  - name: "${name}"
                    checks:
                      - http: "http://${haproxy_user}:${haproxy_pass}@127.0.0.1:8282"
                        method: "GET"
                        interval: "2s"
                  - name: "exporter_node"
                    port: 9100
                  - name: "exporter_haproxy"
                    port: 9101
                rejoin_after_leave: true
                retry_join:
                  - "${consul}"
          - role: entercloudsuite.keepalived
            keepalived_options:
              - name: log-detail
            keepalived_vrrp_scripts:
              chk_haproxy:
                script: '/bin/pidof haproxy'
                weight: 100
                interval: 1

            keepalived_vrrp_instances:
              VI_1:
                interface: "{{ ansible_default_ipv4.interface }}"
                state: "{% if ${number} == 0 %}MASTER{% else %}BACKUP{% endif %}"
                priority: "{{ 110 - ${number}0 }}"
                virtual_router_id: ${haproxy_virtual_router_id_0}
                authentication:
                  auth_type: PASS
                  auth_pass: '${haproxy_pass}'
                virtual_ipaddresses:
                  - '${haproxy_vip_0}/${haproxy_subnet} dev {{ ansible_default_ipv4.interface }} label {{ ansible_default_ipv4.interface }}:1'
                track_scripts:
                  - chk_haproxy

              VI_2:
                interface: "{{ ansible_default_ipv4.interface }}"
                state: "{% if ${number} == 0 %}BACKUP{% else %}MASTER{% endif %}"
                priority: "{{ 110 - ${number}1 }}"
                virtual_router_id: ${haproxy_virtual_router_id_1}

                authentication:
                  auth_type: PASS
                  auth_pass: '${haproxy_pass}'

                virtual_ipaddresses:
                  - '${haproxy_vip_1}/${haproxy_subnet} dev {{ ansible_default_ipv4.interface }} label {{ ansible_default_ipv4.interface }}:1'

                track_scripts:
                  - chk_haproxy


    path: /usr/src/cloud/playbook.yml
    permissions: '0400'

runcmd:
  - |
      bash <<'EOF'
      export COMPLETED=false
      while [ "$COMPLETED" == "false" ]; do
        (
          set -e errexit
          set -o pipefail
          # workaround https://github.com/ansible/ansible/issues/21562
          export HOME=/root
          cd /usr/src/cloud
          source venv/bin/activate
          ansible-playbook -e ansible_python_interpreter=/usr/bin/python --connection=local playbook.yml
        ) >> /var/log/cloud-scripts.log 2>&1
        if [ $? == 0 ]; then
          COMPLETED=true
        fi
        sleep 1
      done
      EOF
